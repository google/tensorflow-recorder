{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Google Cloud DataFlow with TFRecorder\n",
    "\n",
    "This notebook demonstrates how to use TFRecorder with Google Cloud DataFlow to scale up to processing any size of dataset.\n",
    "    \n",
    "## Notebook Setup\n",
    "\n",
    "1. Please install TFRecorder with the command `python setup.py` from the repository root.\n",
    "\n",
    "2. Create a new GCS bucket the command with `gsutil mb gs://your/bucket/name/` and set the BUCKET= constant to that name.\n",
    "\n",
    "3. Copy the test images from the TFRutil repo to the new gcs bucket with the command `gsutil cp -r  ./tfrutil/test_data/images gs://<BUCKET_NAME/images`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tfrecorder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip download tfrecorder --no-deps\n",
    "!cp tfrecorder* /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET=\"\" # ADD YOUR BUCKET HERE, E.G. \"GS://MYBUCKET/\"\n",
    "PROJECT=\"\" # ADD YOUR PROJECT NAME HERE\n",
    "REGION=\"\" # ADD A COMPUTE REGION HERE\n",
    "OUTPUT_PATH = \"results/\"\n",
    "TFRECORDER_WHEEL = \"/tmp/tfrecorder-0.1.1-py3-none-any.whl\" #UPDATE VERSION AS NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update image_uri \n",
    "\n",
    "The image_uri column is currently pointing to the local file locations for each test image. We will change this path to the new GCS location below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_uri'] = df.image_uri.str.replace(\"../tfrecorder/\", BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.tensorflow.to_tfr(output_dir=BUCKET + OUTPUT_PATH,\n",
    "                     runner=\"DataflowRunner\",\n",
    "                     project=PROJECT,\n",
    "                     region=REGION,\n",
    "                     tfrecorder_wheel=TFRECORDER_WHEEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's it!\n",
    "\n",
    "As you can see, TFRecorder has taken the supplied CSV and transformed it into TFRecords, ready for consumption, along with the transform function"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
